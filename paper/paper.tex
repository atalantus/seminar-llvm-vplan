\documentclass[sigplan,11pt,nonacm]{acmart}
\settopmatter{printfolios}

\usepackage{booktabs} % For formal tables
\usepackage{subcaption}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{pgfplotstable}
\usepackage{hyphenat}
\usepackage{todonotes}
\usepackage[babel]{csquotes}


\begin{document}
\title{Utilizing Parallel Workers: \\LLVM's Vectorization Plan}
\author{Jonas Fritsch}
\affiliation{%
  \institution{Technical University of Munich}
}
\email{jonas.fritsch@tum.de}

\begin{abstract}
Lorem ipsum
\end{abstract}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Introduction}
\label{sec:introduction}
Modern CPUs are often equipped with multiple different vector registers. These registers are nowadays 
as wide as 512 bits, allowing for the processing of multiple data streams at once (SIMD). By 
batching multiple values together in one register, different ISAs like Intel AVX or ARM SVE allow 
the execution of the same instruction for all values in a vector register simultaneously. 
Utilizing this leads to significant performance improvements over the scalar equivalent most of 
the time.

However, as manual code vectorization can quickly become very time-consuming, especially when
supporting different CPU architectures, modern compilers aim to automatically transform scalar code
to use vectorization when applicable.

As one of the most widely used compilation frameworks, LLVM~\cite{10.5555/977395.977673} has 
implemented and refined its auto-vectorization over many years. It provides two different 
Vectorizers, one for innermost loops (LoopVectorize) and one for super-word parallelism 
(SLPVectorize)~\cite{llvmvec}.

This system, however, had quite a few limitations, as the loop vectorizer could only handle
innermost loops and neither outer loops, complex control flow, nor non-inlined functions. 
Additionally, while multiple different vectorizations for the same scalar code 
would be possible, the current vectorizers working directly on the LLVM IR could not model
and compare the costs of such different vectorization approaches.

With these limitations in mind, Intel started an ongoing refactorization effort to migrate LLVM's
auto-vectorization pipeline to utilize a more abstract Vectorization Plan 
(VPlan)~\cite{llvmextloopvec,llvmvplan}. The final goal would be to unite LLVM's auto-vectorization
in a single flexible system capable of optimizing SLPs, inner, and nested loops with complex 
control flows. The auto-vectorization pass would create and transform multiple different 
VPlans, each modeling a different vectorization approach, abstracted away from the underlying LLVM IR.
Those VPlans are compared against each other based on a cost model and finally the best one, which
might also be not to vectorize at all, is materialized into the LLVM IR.

LLVM's VPlan is currently being integrated into the existing Loop Vectorizer and is
already modeling most inner loop vectorizations and transformations~\cite{llvmvplanupdate}. 
Vectorization for outer loops is also in development and can be enabled by setting 
the \texttt{-enable-vplan-native-path} flag~\cite{llvmouterloop}. In the future, the plan will 
be to merge both of these loop vectorization paths into one.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Background}
\label{sec:background}
Modern SIMD ISAs like Intel AVX, ARM NEON or even vector-length agnostic ISAs like ARM SVE provide
a variety of different instructions to allow vectorization of even complex control flows. To lower
the complexity for implementing auto-vectorization, the general optimizations are often seperated
into different categories:

\subsection{Inner Loop Vectorization}
Innermost loops are loops whose body's control flow does not contain any more loops, bound or unbound.
Vectorization of these loops are simpler in comparison as the only option to vectorize is over the
loop's induction variable.

There are various ways to transform the control flow of a loop to accomodate operating on widened
vector registers. Figure \ref{fig:inner-loop-vec} shows an example of an if-conversion. Some more
examples can also be found in LLVM's Auto-Vectorization Documentation~\cite{llvmvec}.

\begin{figure}
  \centering
  \includegraphics[width=0.35\textwidth]{images/inner-loop-vec.png}
  \caption{A code snippet of a simple loop that would be vectorized over the variable \texttt{i}. 
  The conditional branch would be flattened into a masked-addition. The mask would be generated 
  based on \texttt{z[i]}.}
  \label{fig:inner-loop-vec}
\end{figure}

\subsection{Super-Word Parallelism (SLP) Vectorization}
SLP Vectorization vectorizes similar independent instructions. In the context of auto-vectorization a 
compiler might have, for example, fully unrolled a smaller loop in a previous simplifcation pass. 
The resulting similar scalar instructions might then be vectorized later on by an SLP vectorizer.

\subsection{Outer Loop Vectorizaton}
Outer loop vectorization focuses on control flow with nested loops. Such loops often present
more challenges for auto-vectorization, as one could possibly vectorize over the outer loop,
the inner loop or a mix of both, representing a hybrid/multi-dimensional vectorization approach. Carrying out and
comparing costs of such different vectorization approaches/transformations can be complex and
require a flexible system like VPlans. 

Figure \ref{fig:outer-loop-vec} shows a nested loop code-snippet where vectorization over the
outer loop would be beneficial.

\begin{figure}
  \centering
  \includegraphics[width=0.39\textwidth]{images/outer-loop-vec.png}
  \caption{A code snippet of a nested loop where it would be beneficial to vectorize over the 
  outer loop. As the inner loop has a too low trip count (6) to vectorize and additionally
  the memory access pattern of \texttt{y} would be adjacent compared to scattered when
  vectorizing over \texttt{i} instead of \texttt{j}.}
  \label{fig:outer-loop-vec}
\end{figure}

\subsection{Function Vectorization}
Function vectorization refers to the vectorization of full functions. A loop might contain a
function call, that can not be inlined, passing data related to the iteration variable. During
auto-vectorization this call would possibly be replaced with a call to a newly constructed function 
with the same semantic control flow but operating on multiple values at once through vector
registers instead.

\subsection{Vectorization Similarities}
All of the above mentioned vectorization categories can be brought into relatation with each other. 
For example function vectorization can be transformed into loop vectorization by creating a loop 
around the function body and vectorizing it and vice versa. Similar is true for SLP Vectorization 
and loop vectorization by unrolling a loop.
 
\subsection{Vectorization Legality}
Not all loops can be vectorized. There are various factors that can completely hinder any
vectorization attempts.

% TODO

\subsection{Vectorization Costs}
While it may just not be legal to vectorize a given control flow, sometimes the vectorized code 
might also just perform worse than its scalar equivalent.

Some control flow transformations that seem beneficial at compile time might reveal a performance
bottleneck at runtime. Considering the code snippet from Figure \ref{fig:inner-loop-vec}, it might
be that at runtime almost all of \texttt{z[i]} evaluate to false. The branch predictor of a CPU
would then be able to guess the correct branch in the scalar code. The vectorized version would
always load the \texttt{y[i]} into memory only for the addition to be masked away. There are
different approaches to avoid such runtime penalties such as branch-on-superword-condition code 
(BOSCC)~\cite{10.5555/1299042.1299055,llvmboscc} or active-lane 
consolidation (ALC)~\cite{10.1007/s11227-022-04359-w,10.5555/3615924.3615932}.

Some vector instructions can be quite costly on most CPUs. An example would be gather/scatter
or shuffeling and permutation instructions. Control flow with a lot of non-adjacent 
memory load/stores or operations that combine different vector elements such as reductions
can decrease vectorization performance.

Additionally the vectorized code size will always be larger than the scalar equivalent. This is
due to many factors: (1) The transformed control flow oftentimes simply includes more instructions.
(2) As the loop trip count might not be a perfect multiple of the vectorization factor, a scalar
epilogue/remainder of the loop might be used to handle the tail iterations. (3) Various runtime
checks might be inserted throughout the vectorized control flow to handle 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{LLVM's Vectorization Plan}
\label{sec:vplan}
Lorem ipsum


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Related Work}
\label{sec:relatedwork}
Lorem ipsum


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Summary and Future Work}
\label{sec:summary}
Lorem ipsum


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\bibliographystyle{ACM-Reference-Format}
\bibliography{paper} % read paper.bib file

\end{document}
